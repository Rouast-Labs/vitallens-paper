\documentclass{article}

\usepackage[final]{assets/techreport}
%\usepackage[nonatbib]{assets/techreport}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{pgfplots}
\usepackage{subcaption}

\title{VitalLens 1.0 Technical Report}

\author{%
  Philipp V.~Rouast \\
  Rouast Labs\\
  \texttt{philipp@rouast.com} \\
}


\begin{document}


\maketitle


\begin{abstract}
We report the development of VitalLens, an app that estimates vital signs such as heart rate and respiration rate from selfie video in real time.
The estimation engine of VitalLens is a computer vision model trained on a diverse dataset of video and gold-standard ground truth physiological sensor data.
% TODO: Summarize findings
\end{abstract}


\section{Introduction}

Video of the human face and upper body contains signals with information about the subject's physiological state.
Given appropriate circumstances, these signals can be strong enough to estimate vital signs such as heart rate and respiratory rate.
This process is known as Remote Photoplethysmography (rPPG); many rPPG approaches have been proposed, including handcrafted algorithms and ones learned from empirical data.
Depending on the intended application, we can measure advantages and drawbacks of rPPG approaches in the accuracy, inference speed, and robustness regarding various factors impacting estimation performance.

Paragraph on G, CHROM, and POS.

Paragraph on DeepPhys and MTTS-CAN.

Acknowledge other models we don't compare because lack focus on real-time.

\section{Scope and Limitations of this Technical Report}
\label{gen_inst}

This report focuses on the capabilities and limitations of VitalLens.
The estimation engine of VitalLens is a recurrent convolutional model trained on a diverse dataset of video and gold-standard ground truth physiological data.

This report does not contain any further detail about the architecture of the model or training methodology -
we reserve this for future publication.

\section{Datasets}
\label{headings}

Two major datasets are involved with training and evaluation of VitalLens:
The \textit{PROSIT} dataset and the \textit{Vital Videos} dataset.
The vast majority of the data used to train VitalLens comes from PROSIT.
We enrich the training data with a subset of data from the Vital Videos dataset, as detailed in this section.
The main Vital Videos dataset serves as a test set for the evaluation of VitalLens.

\subsection{PROSIT}

PROSIT (\underline{P}hysiological \underline{R}ecordings \underline{O}f \underline{S}ubjects using \underline{I}maging \underline{T}echnology) is our in-house dataset for practical rPPG applications.

\paragraph{Participant recruitment and session protocol.} 
As part of our goal of creating a diverse rPPG dataset for practical applications, we recruit participants and collect data at various locations such as residential homes, offices, libraries, and clubs.
Each potential participant was required to go through an informed consent process in accordance with Australian privacy laws prior to participation.
During the session, participants are asked to complete tasks on an iPad while sensor data is being recorded.

\paragraph{Sensors and collected data.}
The time-synchronized sensor array used for PROSIT consists of a video camera, electrocardiogram (ECG), pulse oximetry, blood pressure monitor, and an ambient light sensor.
This yields a rich set of data including video, ECG, PPG, SpO2, respiration, blood pressure, and ambient luminance.
We also collect age, gender, height, and skin type metadata according to the Fitzpatrick scale.

\paragraph{Pre-processing.}
We pre-process and split each session into small chunks of 5-20 seconds with valid video and signals.
As part of this step, we also calculate summary vitals for each chunk from the continuous signals, and extract further metadata such as the amount of participant movement and illumination variation.

\paragraph{Dataset size and split.}
Development of PROSIT is ongoing.
As of the writing of this report, it comprises 157 unique participants across 173 recording sessions in 45 different locations.
This results in a total of 9,767 chunks or 27.8 hours of data.

\begin{table}[h!]
  \caption{PROSIT Dataset Size}
  \label{prosit-table}
  \centering
  \begin{tabular}{llll}
    \toprule
    Split      & \# Participants & \# Chunks & Time   \\
    \midrule
    Training   & 114 			 & 6,765     & 19.4 h \\
    Validation & 23 			 & 1,599     & 4.5 h  \\
    Test       & 20     			 & 1,403     & 3.9 h  \\
    \midrule
    Total      & 157			 & 9,767  	 & 27.8 h \\
    \bottomrule
  \end{tabular}
\end{table}

Each participant is randomly assigned to be part of either the \textit{training}, \textit{validation}, or \textit{test} set to ensure that all participants seen during validation and test are previously unseen by the model.

\paragraph{Participant diversity.}
The skin type diversity of PROSIT is lacking, with too many type 2 and too few type 5 and 6 participants.
This is why we additionally use the Vital Videos Ghana training set when training our model.

TODO: Histogram of ages x n participants

\begin{figure}[h!]
    \centering
    \begin{subfigure}{0.48\textwidth}
    	\centering
    	\begin{tikzpicture}
        	\begin{axis}[
            		table/col sep=comma,
            		ybar,
            		ylabel=Frequency,
            		xlabel={Heart rate [bpm]},
            		xmin=35,
            		xmax=130,
            		width=\textwidth,
            		height=5cm,
            		grid=major,
            		bar width=12pt
            	]
            	\addplot[fill=red!60,opacity=0.8] table[x index=0, y index=1] {hr_histogram.csv};
        	\end{axis}
    	\end{tikzpicture}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.48\textwidth}
    	\centering
    	\begin{tikzpicture}
        	\begin{axis}[
            		table/col sep=comma,
            		ybar,
            		ylabel=Frequency,
            		xlabel={Respiratory rate [rpm]},
            		xmin=-2,
            		xmax=40,
            		width=\textwidth,
            		height=5cm,
            		grid=major,
            		bar width=12pt
            	]
            	\addplot[fill=blue!60,opacity=0.8] table[x index=0, y index=1] {rr_histogram.csv};
        	\end{axis}
    	\end{tikzpicture}
    \end{subfigure}
	\begin{subfigure}{0.48\textwidth}
    	\centering
    	\begin{tikzpicture}
        	\begin{axis}[
            		table/col sep=comma,
            		ybar,
            		ylabel=Frequency,
            		xlabel={Blood pressure [mmHg]},
            		xmin=50,
            		xmax=170,
            		width=\textwidth,
            		height=5cm,
            		grid=major,
            		legend style={at={(.98,.97)}, anchor=north east},
            	]
            	\addplot[ybar,bar width=10pt,fill=blue!60,opacity=0.8] table[x index=0, y index=1] {bp_sys_histogram.csv};
            	\addlegendentry{SBP}
            	\addplot[ybar,bar width=7pt,fill=red!60,opacity=0.7] table[x index=0, y index=1] {bp_dia_histogram.csv};
            	\addlegendentry{DBP}
        	\end{axis}
    	\end{tikzpicture}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.48\textwidth}
    	\centering
    	\begin{tikzpicture}
        	\begin{axis}[
            		table/col sep=comma,
            		ybar,
            		ylabel=Frequency,
            		xlabel={SpO2 [\%]},
            		xmin=87,
            		xmax=101,
            		width=\textwidth,
            		height=5cm,
            		grid=major,
            		bar width=12pt
            	]
            	\addplot[fill=blue!60,opacity=0.8] table[x index=0, y index=1] {spo2_histogram.csv};
        	\end{axis}
    	\end{tikzpicture}
    \end{subfigure}
    \caption{Distributions of chunk summary vitals in PROSIT}
    \label{fig:histogram}
\end{figure}

TODO: Histogram of skin types x n participants
TODO: Histogram of genders x n participants1 

\paragraph{Vitals diversity.}
There are also several participants who have an irregular heartbeat.

TODO: Histogram of HR x n chunks
TODO: Histogram of RR x n chunks
TODO: Histogram of BP x n chunks
TODO: Histogram of SpO2 x n chunks

\subsection{Vital Videos}

\subsubsection{Vital Videos Medium}

Used for test.

Pieter's dataset
Number of unique subjects
Total duration
Statistics
Distributions of metadata

\subsubsection{Vital Videos Ghana}

Used for training.

Pieter's dataset
Number of unique subjects
Total duration
Statistics
Distributions of metadata


\section{Methodology}
\label{others}

?

\section{Results and Discussion}

\subsection{Vitals estimation}

Table comparing G, CHROM, POS, DeepPhys, MTTS-CAN, VitalLens

\subsection{Which factors impact estimation performance?}

Regression analysis to determine factors impacting estimation performance

\subsection{Impact of subject movement}

Bar chart comparing G, CHROM, POS, DeepPhys, MTTS-CAN, VitalLens SNR or MAE estimating HR - vs subject movement on x axis.
Bar chart comparing DeepPhys, MTTS-CAN, VitalLens SNR or MAE estimating RR - vs subject movement on x axis.

\subsection{Impact of illumination variation}

Bar chart comparing G, CHROM, POS, DeepPhys, MTTS-CAN, VitalLens SNR estimating HR - vs illumination variation on x axis.

\subsection{Impact of subject skin type}

Bar chart comparing G, CHROM, POS, DeepPhys, MTTS-CAN, VitalLens SNR estimating HR - vs subject skin type on x axis.

\subsection{Impact of subject age}

Bar chart comparing G, CHROM, POS, DeepPhys, MTTS-CAN, VitalLens SNR estimating HR - vs subject age on x axis.

\section{Conclusion}

Authors may wish to optionally include extra information (complete proofs, additional experiments and plots) in the appendix. All such materials should be part of the supplemental material (submitted separately) and should NOT be included in the main submission.


\section*{References}


References follow the acknowledgments in the camera-ready paper. Use unnumbered first-level heading for
the references. Any choice of citation style is acceptable as long as you are
consistent. It is permissible to reduce the font size to \verb+small+ (9 point)
when listing the references.
Note that the Reference section does not count towards the page limit.
\medskip


{
\small


[1] Alexander, J.A.\ \& Mozer, M.C.\ (1995) Template-based algorithms for
connectionist rule extraction. In G.\ Tesauro, D.S.\ Touretzky and T.K.\ Leen
(eds.), {\it Advances in Neural Information Processing Systems 7},
pp.\ 609--616. Cambridge, MA: MIT Press.


[2] Bower, J.M.\ \& Beeman, D.\ (1995) {\it The Book of GENESIS: Exploring
  Realistic Neural Models with the GEneral NEural SImulation System.}  New York:
TELOS/Springer--Verlag.


[3] Hasselmo, M.E., Schnell, E.\ \& Barkai, E.\ (1995) Dynamics of learning and
recall at excitatory recurrent synapses and cholinergic modulation in rat
hippocampal region CA3. {\it Journal of Neuroscience} {\bf 15}(7):5249-5262.
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}