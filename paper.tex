\documentclass{article}

\usepackage[final]{assets/techreport}
%\usepackage[nonatbib]{assets/techreport}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{pgfplots}
\usepackage{subcaption}
\usepackage{csvsimple}
\usepackage{siunitx}
\sisetup{group-separator = {,}, group-minimum-digits = 4}

\title{VitalLens: Take A Vital Selfie}

\author{%
  Philipp V.~Rouast \\
  Rouast Labs\\
  \texttt{philipp@rouast.com} \\
}


\begin{document}


\maketitle


\begin{abstract}
This report introduces VitalLens, an app that estimates vital signs such as heart rate and respiration rate from selfie video in real time.
The estimation engine of VitalLens is a computer vision model trained on a diverse dataset of video and gold-standard ground truth physiological sensor data.
% TODO: Summarize findings
\end{abstract}


\section{Introduction}

Video of the human face and upper body contains signals with information about the subject's physiological state \citep{verkruysse2008remote}.
Given appropriate circumstances, these signals can be strong enough to estimate vital signs such as heart rate and respiratory rate.
This process is known as Remote Photoplethysmography (rPPG); many rPPG approaches have been proposed, including handcrafted algorithms and ones learned from empirical data.
Depending on the intended application, we can measure advantages and drawbacks of rPPG approaches in the accuracy, inference speed, and robustness regarding various factors impacting estimation performance.

Paragraph on G \cite{verkruysse2008remote}, CHROM \cite{de2013robust}, and POS \cite{wang2017algorithmic}.

Paragraph on DeepPhys \cite{chen2018deep} and MTTS-CAN \cite{liu2020multi}.

Acknowledge other models we don't compare because lack focus on real-time.

[INSERT FIGURE WITH SAMPLE PREDICTIONS FROM VALIDATION SET]

Section summarizing the remainder of the report.

\section{Scope and Limitations of this Technical Report}
\label{gen_inst}

This report focuses on the capabilities and limitations of VitalLens.
The estimation engine of VitalLens is a computer vision model trained on a diverse dataset of video and gold-standard ground truth physiological data.

This report does not contain any further detail about the architecture of the model or training methodology -
we reserve this for future publication.

\section{Datasets}
\label{headings}

VitalLens is trained on the \textit{PROSIT} and \textit{Vital Videos Ghana} datasets.
The vast majority of training data comes from PROSIT.
For evaluation, we use the entire \textit{Vital Videos Medium} dataset as well as the test sets of the \textit{PROSIT} and \textit{Vital Videos Ghana} datasets.

\subsection{PROSIT}

PROSIT (\underline{P}hysiological \underline{R}ecordings \underline{O}f \underline{S}ubjects using \underline{I}maging \underline{T}echnology) is our in-house dataset collected in Australia for practical rPPG applications.

\paragraph{Participant recruitment and session protocol.} 
As part of our goal of creating a diverse rPPG dataset for practical applications, we recruit participants and collect data at various locations such as residential homes, offices, libraries, and clubs.
Each potential participant was required to go through an informed consent process in accordance with Australian privacy laws prior to participation.
During the session, participants are asked to complete tasks on an iPad while sensor data is being recorded.

\paragraph{Sensors and collected data.}
The time-synchronized sensor array used for PROSIT consists of a video camera, electrocardiogram (ECG), pulse oximetry, blood pressure monitor, and an ambient light sensor.
This yields a rich set of data including video, ECG, PPG, SpO2, respiration, blood pressure, and ambient luminance.
We also collect age, gender, height, and skin type metadata according to the Fitzpatrick scale.

\paragraph{Pre-processing.}
We pre-process and split each session into small chunks of 5-20 seconds with valid video and signals.
As part of this step, we also calculate summary vitals for each chunk from the continuous signals, and extract further metadata such as the amount of participant movement and illumination variation.

\paragraph{Dataset size and split.}
\csvreader[before reading=\def\totalparticipantsprosit{0}\def\totalchunksprosit{0}\def\totaltimeprosit{0}\def\totalsessionsprosit{0}]{data/prosit_summary.csv}{participants=\participants,chunks=\chunks,time=\time,sessions=\sessions}{%
	\pgfmathsetmacro{\totalparticipantsprosit}{\totalparticipantsprosit+\participants}%
	\pgfmathsetmacro{\totalchunksprosit}{\totalchunksprosit+\chunks}%
	\pgfmathsetmacro{\totaltimeprosit}{\totaltimeprosit+\time}%
	\pgfmathsetmacro{\totalsessionsprosit}{\totalsessionsprosit+\sessions}%
}
Development of PROSIT is ongoing.
As of the writing of this report, it comprises \sisetup{round-mode=places,round-precision=0}\num{\totalparticipantsprosit} unique participants across \sisetup{round-mode=places,round-precision=0}\num{\totalsessionsprosit} recording sessions in 45 different locations.
This results in a total of \sisetup{round-mode=places,round-precision=0}\num{\totalchunksprosit} chunks or \sisetup{round-mode=places,round-precision=1}\num{\totaltimeprosit} hours of data.

\begin{table}[h!]
 	\caption{PROSIT Dataset Size}
 	\label{tab:prosit-summary}
 	\centering
  	\csvreader[
		tabular=llll,
    	table head=\toprule Split & \# Participants & \# Chunks & Time \\ \midrule,
    	table foot=\midrule Total & \sisetup{round-mode=places,round-precision=0}\num{\totalparticipantsprosit} & \sisetup{round-mode=places,round-precision=0}\num{\totalchunksprosit} & \sisetup{round-mode=places,round-precision=1}\SI{\totaltimeprosit}{\hour} \\ \bottomrule,
    	late after line=\\,
    	before reading={\catcode`\%=12}, after reading={\catcode`\%=14}
  	]{data/prosit_summary.csv}{}%
  {\csvcoli & \num{\csvcolii} & \num{\csvcoliv} & \SI{\csvcolv}{\hour} }
\end{table}

Each participant is randomly assigned to be part of either the \textit{training}, \textit{validation}, or \textit{test} set to ensure that all participants seen during validation and test are previously unseen by the model.

\subsection{Vital Videos Medium}

Vital Videos is a large, diverse dataset for rPPG collected in Belgium \cite{toye2023vital}.
It is the largest dataset we are aware of that is available for research without academic affiliation.
We use a slightly extended version of the medium instantiation (``VV-Medium''), which consists of 296 participants.

\paragraph{Pre-processing.}

We pre-process VV-Medium using the same steps applied to PROSIT.
As part of this step, we create small chunks, calculate summary vitals, and extract further metadata.

\begin{table}[h!]
 	\caption{VV-Medium Dataset Size}
 	\label{tab:vv-medium-summary}
 	\centering
  	\csvreader[
		tabular=llll,
    	table head=\toprule Split & \# Participants & \# Chunks & Time \\ \midrule,
    	table foot=\bottomrule,
    	late after line=\\,
    	before reading={\catcode`\%=12}, after reading={\catcode`\%=14}
  	]{data/vv_medium_summary.csv}{}%
  {\csvcoli & \num{\csvcolii} & \num{\csvcoliii} & \SI{\csvcoliv}{\hour} }
\end{table}

The entirety of VV-Medium is used to test the capabilities of VitalLens.

\subsection{Vital Videos Ghana}

Vital Videos Ghana is a new dataset from the authors of Vital Videos aiming to address the insufficient share of participants with skin types 5 and 6 usually found in rPPG datasets.
It was collected in Ghana, with the majority of participants having skin type 5 or 6.
\csvreader[before reading=\def\totalparticipantsvvghana{0}\def\totalchunksvvghana{0}\def\totaltimevvghana{0}]{data/vv_ghana_small_summary.csv}{participants=\participants,chunks=\chunks,time=\time}{%
	\pgfmathsetmacro{\totalparticipantsvvghana}{\totalparticipantsvvghana+\participants}%
	\pgfmathsetmacro{\totalchunksvvghana}{\totalchunksvvghana+\chunks}%
	\pgfmathsetmacro{\totaltimevvghana}{\totaltimevvghana+\time}%
}
We use a small instantiation (``VV-Ghana-Small''), which consists of \sisetup{round-mode=places,round-precision=0}\num{\totalparticipantsvvghana} participants.

\paragraph{Pre-processing.}

We pre-process VV-Ghana-Small using the same steps applied to PROSIT.
As part of this step, we create small chunks, calculate summary vitals, and extract further metadata.

\begin{table}[h!]
 	\caption{VV-Ghana-Small Dataset Size}
 	\label{tab:vv-ghana-small-summary}
 	\centering
  	\csvreader[
		tabular=llll,
    	table head=\toprule Split & \# Participants & \# Chunks & Time \\ \midrule,
    	table foot=\midrule Total & \sisetup{round-mode=places,round-precision=0}\num{\totalparticipantsvvghana} & \sisetup{round-mode=places,round-precision=0}\num{\totalchunksvvghana} & \sisetup{round-mode=places,round-precision=1}\SI{\totaltimevvghana}{\hour} \\ \bottomrule,
    	late after line=\\,
    	before reading={\catcode`\%=12}, after reading={\catcode`\%=14}
  	]{data/vv_ghana_small_summary.csv}{}%
  {\csvcoli & \num{\csvcolii} & \num{\csvcoliii} & \sisetup{round-mode=places,round-precision=1}\SI{\csvcoliv}{\hour} }
\end{table}

Each participant is randomly assigned to be part of either the \textit{training}, \textit{validation}, or \textit{test} set to ensure that all participants seen during validation and test are previously unseen by the model.

\subsection{Final training dataset: PROSIT + VV-Ghana-Small}
\csvreader[before reading=\def\totalparticipantstraining{0}\def\totalchunkstraining{0}\def\totaltimetraining{0}]{data/training_summary.csv}{participants=\participants,chunks=\chunks,time=\time}{%
		\pgfmathsetmacro{\totalparticipantstraining}{\totalparticipantstraining+\participants}%
		\pgfmathsetmacro{\totalchunkstraining}{\totalchunkstraining+\chunks}%
		\pgfmathsetmacro{\totaltimetraining}{\totaltimetraining+\time}%
	}
We combine the training sets of PROSIT and VV-Ghana-Small for training.
As of this writing, this makes a total of \sisetup{round-mode=places,round-precision=0}\num{\totalparticipantstraining} unique participants, \sisetup{round-mode=places,round-precision=0}\num{\totalchunkstraining} chunks or \sisetup{round-mode=places,round-precision=1}\num{\totaltimetraining} hours of data.

\begin{table}[h!]
 	\caption{VitalLens Training Dataset Size}
 	\label{tab:training-summary}
 	\centering
  	\csvreader[
		tabular=llll,
    	table head=\toprule Source & \# Participants & \# Chunks & Time \\ \midrule,
    	table foot=\midrule Total & \sisetup{round-mode=places,round-precision=0}\num{\totalparticipantstraining} & \sisetup{round-mode=places,round-precision=0}\num{\totalchunkstraining} & \sisetup{round-mode=places,round-precision=1}\SI{\totaltimetraining}{\hour} \\ \bottomrule,
    	late after line=\\,
    	before reading={\catcode`\%=12}, after reading={\catcode`\%=14}
  	]{data/training_summary.csv}{}%
  {\csvcoli & \num{\csvcolii} & \num{\csvcoliii} & \sisetup{round-mode=places,round-precision=1}\SI{\csvcoliv}{\hour} }
\end{table}

\paragraph{Dataset demographics.}
The demographics of our training dataset are given in Figure \ref{fig:training-demographics}.
The participants are predominantly on the younger side, but as we show in Section \ref{results}, this is not an issue in practice.
Genders are equally represented.
Although the skin type diversity of PROSIT by itself is lacking, this combined training dataset has a diverse representation of skin types.
As we show in Section \ref{results}, this helps us to reduce the skin type bias of VitalLens.

% Modified example from www.texample.net for pie charts
% This example needs the packages tikz, xcolor, calc
\definecolorseries{myseries}{rgb}{step}[rgb]{.95,.85,.55}{.17,.47,.37}
\resetcolorseries{myseries}%

% a pie slice
\newcommand{\slice}[4]{
	\pgfmathsetmacro{\midangle}{0.5*#1+0.5*#2}
	\begin{scope}
		\clip (0,0) -- (#1:1) arc (#1:#2:1) -- cycle;
		\colorlet{SliceColor}{myseries!!+}%
		\fill[inner color=SliceColor!30,outer color=SliceColor!60] (0,0) circle (1cm);
	\end{scope}
	\draw[thick] (0,0) -- (#1:1) arc (#1:#2:1) -- cycle;
	\node[label={[font=\small]\midangle:#4}] at (\midangle:1) {};
	\pgfmathsetmacro{\temp}{min((#2-#1-10)/110*(-0.3),0)}
	\pgfmathsetmacro{\innerpos}{max(\temp,-0.5) + 0.8}
	\node[font=\small] at (\midangle:\innerpos) {#3};
}

\begin{figure}[h!]
	\centering
    \begin{subfigure}{0.32\textwidth}
    	\centering
    	\begin{tikzpicture}
        	\begin{axis}[
            		table/col sep=comma,
            		ybar,
            		xmin=10,
            		xmax=95,
            		ylabel=Frequency,
            		width=\textwidth,
            		height=4.6cm,
            		grid=major,
            		bar width=8pt,
            		y label style={yshift=-12pt},
            		label style={inner sep=0pt}
            	]
            	\addplot[fill=blue!60,opacity=0.8] table[x index=0, y index=1] {data/age_histogram.csv};
        	\end{axis}
    	\end{tikzpicture}
    	\caption{Age}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.32\textwidth}
    	\centering
    	% drawing of the pie chart
    	\begin{tikzpicture}[scale=1.5]%
    	\def\mya{0}\def\myb{0}
    	\csvreader[before reading=\def\mysum{0}]{data/gender.csv}{Value=\Value}{%
			\pgfmathsetmacro{\mysum}{\mysum+\Value}%
		}
		\csvreader[head to column names]{data/gender.csv}{}{%
			\let\mya\myb
			\pgfmathsetmacro{\myb}{\myb+\Value}
			\slice{\mya/\mysum*360}{\myb/\mysum*360}{\Value}{\Label}
		}
		\end{tikzpicture}%
		\caption{Gender}
    \end{subfigure}
    \begin{subfigure}{0.32\textwidth}
    	\centering
    	% drawing of the pie chart
    	\begin{tikzpicture}[scale=1.5]%
    	% sum of amounts
		\csvreader[before reading=\def\mysum{0}]{data/skin_type.csv}{Value=\Value}{%
			\pgfmathsetmacro{\mysum}{\mysum+\Value}%
		}
    	\def\mya{0}\def\myb{0}
		\csvreader[head to column names]{data/skin_type.csv}{}{%
			\let\mya\myb
			\pgfmathsetmacro{\myb}{\myb+\Value}
			\slice{\mya/\mysum*360}{\myb/\mysum*360}{\Value}{\Label}
		}
		\end{tikzpicture}%
		\caption{Skin type}
    \end{subfigure}
    \hfill
    \caption{Participant demographics in training dataset}
    \label{fig:training-demographics}
\end{figure}

\paragraph{Vitals diversity.}
Distributions of the vitals in our training dataset are given in Figure \ref{fig:training-vitals-histogram}.
The participants are mostly healthy, so these vitals fall in the typical ranges.
There are several participants who have an irregular heartbeat.

\begin{figure}[h!]
    \centering
    \begin{subfigure}{0.48\textwidth}
    	\centering
    	\begin{tikzpicture}
        	\begin{axis}[
            		table/col sep=comma,
            		ybar,
            		ylabel=Frequency,
            		xlabel={Heart rate [bpm]},
            		xmin=35,
            		xmax=130,
            		width=\textwidth,
            		height=5cm,
            		grid=major,
            		bar width=12pt
            	]
            	\addplot[fill=red!60,opacity=0.8] table[x index=0, y index=1] {data/hr_histogram.csv};
        	\end{axis}
    	\end{tikzpicture}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.48\textwidth}
    	\centering
    	\begin{tikzpicture}
        	\begin{axis}[
            		table/col sep=comma,
            		ybar,
            		ylabel=Frequency,
            		xlabel={Respiratory rate [rpm]},
            		xmin=-2,
            		xmax=40,
            		width=\textwidth,
            		height=5cm,
            		grid=major,
            		bar width=12pt
            	]
            	\addplot[fill=blue!60,opacity=0.8] table[x index=0, y index=1] {data/rr_histogram.csv};
        	\end{axis}
    	\end{tikzpicture}
    \end{subfigure}
    \caption{Distributions of chunk summary vitals in training dataset}
    \label{fig:training-vitals-histogram}
\end{figure}

\section{Methodology}
\label{others}

?

\section{Results and Discussion}
\label{results}

\subsection{Vitals estimation}

Table comparing G, CHROM, POS, DeepPhys, MTTS-CAN, VitalLens

\subsection{Which factors impact estimation performance?}

Regression analysis to determine factors impacting estimation performance

\subsection{Impact of subject movement}

Bar chart comparing G, CHROM, POS, DeepPhys, MTTS-CAN, VitalLens SNR or MAE estimating HR - vs subject movement on x axis.
Bar chart comparing DeepPhys, MTTS-CAN, VitalLens SNR or MAE estimating RR - vs subject movement on x axis.

\subsection{Impact of illumination variation}

Bar chart comparing G, CHROM, POS, DeepPhys, MTTS-CAN, VitalLens SNR estimating HR - vs illumination variation on x axis.

\subsection{Impact of subject skin type}

Bar chart comparing G, CHROM, POS, DeepPhys, MTTS-CAN, VitalLens SNR estimating HR - vs subject skin type on x axis.

\subsection{Impact of subject age}

Bar chart comparing G, CHROM, POS, DeepPhys, MTTS-CAN, VitalLens SNR estimating HR - vs subject age on x axis.

\section{Conclusion}

Authors may wish to optionally include extra information (complete proofs, additional experiments and plots) in the appendix. All such materials should be part of the supplemental material (submitted separately) and should NOT be included in the main submission.

\section*{References}

\bibliographystyle{plain}
\bibliography{paper}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}